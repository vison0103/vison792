{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LypBg6RKqvG9","executionInfo":{"status":"ok","timestamp":1718834304872,"user_tz":-720,"elapsed":2913,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"9eeca7ec-0af6-49cf-88b3-5eb4208e4f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","os.chdir(\"/content/drive/MyDrive/myvit/covnext_t\") # 再跳转到我们刚刚下载好的apex项目文件夹中"],"metadata":{"id":"ffLQ2FxwBUlc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GTSRB\n","import zipfile\n","with zipfile.ZipFile(\"/content/drive/MyDrive/myvit/datasets.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/\") # 我使用的解压位置"],"metadata":{"id":"ZSjG6g1mq1Or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#BTsd\n","import zipfile\n","with zipfile.ZipFile(\"/content/drive/MyDrive/myvit/BelgiumTSC.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/BelgiumTSC\") # 我使用的解压位置"],"metadata":{"id":"jAtDvkRXq1_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TSRD\n","import zipfile\n","with zipfile.ZipFile(\"/content/drive/MyDrive/myvit/TSRD_dataset.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/TSRD\") # 我使用的解压位置"],"metadata":{"id":"XoYaxqcCq3aD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -V\n","import torch\n","torch.version.cuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"id":"KkwvX6qKq-if","executionInfo":{"status":"ok","timestamp":1718834127644,"user_tz":-720,"elapsed":3873,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"d9f1f186-6894-481a-81ee-a870c9163a27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]},{"output_type":"execute_result","data":{"text/plain":["'12.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeeOczbHsm0_"},"outputs":[],"source":["!pip install timm\n","!pip install einops\n","!pip install datasets\n"]},{"cell_type":"code","source":["import timm"],"metadata":{"id":"wv6itonWh2m3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model_list = timm.list_models(\"mobilenetv3*\")\n","print(model_list)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfd7p7_7h5lE","executionInfo":{"status":"ok","timestamp":1717895947440,"user_tz":-720,"elapsed":342,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"796ee41d-50ca-4cdc-ddc6-67f329127b04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['mobilenetv3_large_075', 'mobilenetv3_large_100', 'mobilenetv3_rw', 'mobilenetv3_small_050', 'mobilenetv3_small_075', 'mobilenetv3_small_100']\n"]}]},{"cell_type":"code","source":["#mobilenetv3_small_050\n","model = timm.create_model('mobilenetv3_large_100', pretrained = False, num_classes = 53)"],"metadata":{"id":"3pb8pTLkk3G9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = timm.create_model('convnext_tiny', pretrained = False, num_classes = 43)"],"metadata":{"id":"t7ZZJsw5hNPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = timm.create_model('mobilevit_s', pretrained = False, num_classes = 43)"],"metadata":{"id":"IasIiDp3idht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#v0\n","# 计算模型的总参数量\n","total_params = sum(p.numel() for p in model.parameters())\n","\n","# 计算可训练的参数量\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Trainable Parameters: {trainable_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CV-M1QSFhHs8","executionInfo":{"status":"ok","timestamp":1717895971762,"user_tz":-720,"elapsed":2,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"c14666a9-dabe-4bcd-b033-55b8ef5c90c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Parameters: 4269925\n","Trainable Parameters: 4269925\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLRADe1Cwr4v"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","import torch.utils.data.distributed\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from sklearn.metrics import classification_report\n","from timm.data.mixup import Mixup\n","from timm.loss import SoftTargetCrossEntropy\n","import cv2\n","import numpy as np\n","import timm\n","from timm.data.mixup import Mixup\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import (Compose, Normalize, RandomHorizontalFlip,\n","                                    RandomResizedCrop, RandomRotation, Resize, ToTensor)\n","from tqdm.notebook import tqdm\n","import warnings\n","import json\n","warnings.filterwarnings(\"ignore\")\n","import time\n","import os\n","import torch.nn.functional as F\n","import torchvision.models as models\n","from einops import rearrange\n","from torch import nn\n","from torch.utils.data import random_split"]},{"cell_type":"code","source":["# 设置全局参数\n","model_lr = 1e-4\n","BATCH_SIZE = 32\n","EPOCHS = 80\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","use_amp=False #是否使用混合精度\n","CLIP_GRAD=5.0\n","# 数据预处理7\n","#p.value.\n","#t.TEST使用如t检验或Wilcoxon符号秩检验"],"metadata":{"id":"8fS0haBCsbO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes=54 #TSRD\n","#classes=43 #GTSRB\n","#classes=53 #BTSD"],"metadata":{"id":"o4fREoXRujBp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),  # 调整明暗度、对比度、饱和度\n","    transforms.RandomRotation(degrees=15),  # 在[-15, 15]度范围内随机旋转\n","    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 在x和y方向上各随机平移图像的10%\n","    transforms.ToTensor()\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","])\n","\n","mixup_fn = Mixup(\n","    mixup_alpha=0.8, cutmix_alpha=0.0, cutmix_minmax=None,\n","    prob=0.1, switch_prob=0.5, mode='batch',\n","    label_smoothing=0.1, num_classes=classes)\n"],"metadata":{"id":"TYzOJ8RWr7Kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#德国\n","dataset_train = datasets.ImageFolder('/content/datasets/train', transform=transform)\n","dataset_test = datasets.ImageFolder('/content/datasets/test', transform=transform_test)\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n","#德国\n","print(dataset_train.class_to_idx)\n","with open('/content/datasets/class.txt','w') as file:\n","    file.write(str(dataset_train.class_to_idx))\n","with open('/content/datasets/class.json','w',encoding='utf-8') as file:\n","    file.write(json.dumps(dataset_train.class_to_idx))"],"metadata":{"id":"bQSe-8ensH6U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718785926440,"user_tz":-720,"elapsed":585,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"493559ae-c64c-4018-aefd-cc8c8fa3dd2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'CarefulBikes': 0, 'CarefulChildren': 1, 'CarefulDangerous': 2, 'CarefulPedestrians': 3, 'CarefulSlipping': 4, 'CarefulSnow': 5, 'CarefulTrafficLight': 6, 'ConstructionRoad': 7, 'LeftTurn': 8, 'MainRoutePriority': 9, 'MustGoStraight': 10, 'MustGoStraightOrLeft': 11, 'MustGoStraightOrRight': 12, 'MustLeftSide': 13, 'MustRightSide': 14, 'MustTurnLeft': 15, 'MustTurnRight': 16, 'NeedsToYield': 17, 'NoAccess': 18, 'NoEntry': 19, 'NoOvertaking': 20, 'NoOvertakingRemove': 21, 'NoOvertakingTrucks': 22, 'NoOvertakingTrucksRemove': 23, 'NoTrucks': 24, 'PriorityRoad': 25, 'RightTurn': 26, 'RoadNarrowing': 27, 'SharpTurn': 28, 'SpeedLimit100': 29, 'SpeedLimit120': 30, 'SpeedLimit20': 31, 'SpeedLimit30': 32, 'SpeedLimit50': 33, 'SpeedLimit60': 34, 'SpeedLimit70': 35, 'SpeedLimit80': 36, 'SpeedLimit80Lifted': 37, 'Stop': 38, 'Turntable': 39, 'UnevenRoad': 40, 'Unrestrict': 41, 'WildAnimals': 42}\n"]}]},{"cell_type":"code","source":["#比利时\n","dataset_train = datasets.ImageFolder('/content/BelgiumTSC/BelgiumTSC/Training', transform=transform)\n","dataset_test = datasets.ImageFolder('/content/BelgiumTSC/BelgiumTSC/Testing', transform=transform_test)\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(dataset_train.class_to_idx)\n","with open('/content/BelgiumTSC/BelgiumTSC/class.txt','w') as file:\n","    file.write(str(dataset_train.class_to_idx))\n","with open('/content/BelgiumTSC/BelgiumTSC/class.json','w',encoding='utf-8') as file:\n","    file.write(json.dumps(dataset_train.class_to_idx))"],"metadata":{"id":"TEb-__JNsKBw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718786660425,"user_tz":-720,"elapsed":726,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"d5ea94a9-35a5-43ea-e8bc-cb6a5eb09785"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'00000': 0, '00001': 1, '00002': 2, '00003': 3, '00004': 4, '00005': 5, '00006': 6, '00007': 7, '00008': 8, '00010': 9, '00012': 10, '00013': 11, '00014': 12, '00016': 13, '00017': 14, '00018': 15, '00019': 16, '00020': 17, '00021': 18, '00022': 19, '00023': 20, '00024': 21, '00025': 22, '00027': 23, '00028': 24, '00029': 25, '00030': 26, '00031': 27, '00032': 28, '00034': 29, '00035': 30, '00037': 31, '00038': 32, '00039': 33, '00040': 34, '00041': 35, '00042': 36, '00043': 37, '00044': 38, '00045': 39, '00046': 40, '00047': 41, '00049': 42, '00051': 43, '00053': 44, '00054': 45, '00055': 46, '00056': 47, '00057': 48, '00058': 49, '00059': 50, '00060': 51, '00061': 52}\n"]}]},{"cell_type":"code","source":["#中国\n","dataset_train = datasets.ImageFolder('/content/TSRD/TSRD_dataset/Train', transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","dataset_test = datasets.ImageFolder('/content/TSRD/TSRD_dataset/Test', transform=transform_test)\n","test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(dataset_train.class_to_idx)\n","with open('/content/TSRD/TSRD_dataset/class.txt','w') as file:\n","    file.write(str(dataset_train.class_to_idx))\n","with open('/content/TSRD/TSRD_dataset/class.json','w',encoding='utf-8') as file:\n","    file.write(json.dumps(dataset_train.class_to_idx))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Npc3Eby_sLoc","executionInfo":{"status":"ok","timestamp":1718834336999,"user_tz":-720,"elapsed":554,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"4ad2748d-1973-4f2e-924a-012b6951104f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'000': 0, '001': 1, '002': 2, '003': 3, '004': 4, '005': 5, '006': 6, '007': 7, '008': 8, '010': 9, '011': 10, '012': 11, '013': 12, '014': 13, '015': 14, '016': 15, '017': 16, '020': 17, '021': 18, '022': 19, '023': 20, '024': 21, '025': 22, '026': 23, '027': 24, '028': 25, '029': 26, '030': 27, '031': 28, '032': 29, '034': 30, '035': 31, '036': 32, '037': 33, '038': 34, '039': 35, '040': 36, '041': 37, '042': 38, '043': 39, '044': 40, '045': 41, '046': 42, '047': 43, '048': 44, '049': 45, '050': 46, '051': 47, '052': 48, '053': 49, '054': 50, '055': 51, '056': 52, '057': 53}\n"]}]},{"cell_type":"code","source":["# 检查训练集和测试集的类别数量\n","train_classes = dataset_train.class_to_idx\n","test_classes = dataset_test.class_to_idx\n","\n","# 打印类别数量\n","print(\"Number of classes in training set:\", len(train_classes))\n","print(\"Number of classes in testing set:\", len(test_classes))\n","\n","# 检查类别数量是否相等\n","if len(train_classes) == len(test_classes):\n","    print(\"Both datasets have the same number of classes.\")\n","else:\n","    print(\"Mismatch in the number of classes between datasets.\")\n","\n","# 检查具体的类别是否一致\n","train_class_set = set(train_classes.keys())\n","test_class_set = set(test_classes.keys())\n","\n","if train_class_set == test_class_set:\n","    print(\"All classes match between training and testing sets.\")\n","else:\n","    print(\"There are differences in class names between the datasets.\")\n","    # 找出不匹配的类别\n","    only_in_train = train_class_set - test_class_set\n","    only_in_test = test_class_set - train_class_set\n","    print(\"Classes only in training set:\", only_in_train)\n","    print(\"Classes only in testing set:\", only_in_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vt25Qb-uJTb","executionInfo":{"status":"ok","timestamp":1718785933580,"user_tz":-720,"elapsed":718,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"9ae32ffb-304e-420e-eb33-068c7a56373f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes in training set: 43\n","Number of classes in testing set: 43\n","Both datasets have the same number of classes.\n","All classes match between training and testing sets.\n"]}]},{"cell_type":"code","source":["#E-MobileViT\n","def _make_divisible(v, divisor, min_value=None):\n","\tif min_value is None:\n","\t\tmin_value = divisor\n","\tnew_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n","\t# Make sure that round down does not go down by more than 10%.\n","\tif new_v < 0.9 * v:\n","\t\tnew_v += divisor\n","\treturn new_v\n","\n","\n","def Conv_BN_ReLU(inp, oup, kernel, stride=1):\n","\treturn nn.Sequential(\n","\t\tnn.Conv2d(inp, oup, kernel_size=kernel, stride=stride, padding=1, bias=False),\n","\t\tnn.BatchNorm2d(oup),\n","\t\tnn.ReLU6(inplace=True)\n","\t)\n","\n","\n","def conv_1x1_bn(inp, oup):\n","\treturn nn.Sequential(\n","\t\tnn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n","\t\tnn.BatchNorm2d(oup),\n","\t\tnn.ReLU6(inplace=True)\n","\t)\n","\n","\n","class PreNorm(nn.Module):\n","\tdef __init__(self, dim, fn):\n","\t\tsuper().__init__()\n","\t\tself.norm = nn.LayerNorm(dim)\n","\t\tself.fn = fn\n","\n","\tdef forward(self, x, **kwargs):\n","\t\treturn self.fn(self.norm(x), **kwargs)\n","\n","\n","class FeedForward(nn.Module):\n","\tdef __init__(self, dim, hidden_dim, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tself.ffn = nn.Sequential(\n","\t\t\tnn.Linear(dim, hidden_dim),\n","\t\t\tnn.SiLU(),\n","\t\t\tnn.Dropout(dropout),\n","\t\t\tnn.Linear(hidden_dim, dim),\n","\t\t\tnn.Dropout(dropout)\n","\t\t)\n","\n","\tdef forward(self, x):\n","\t\treturn self.ffn(x)\n","\n","\n","class Attention(nn.Module):\n","\tdef __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tinner_dim = dim_head * heads\n","\t\tproject_out = not (heads == 1 and dim_head == dim)\n","\n","\t\tself.heads = heads\n","\t\tself.scale = dim_head ** -0.5\n","\n","\t\tself.attend = nn.Softmax(dim=-1)\n","\t\tself.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n","\n","\t\tself.to_out = nn.Sequential(\n","\t\t\tnn.Linear(inner_dim, dim),\n","\t\t\tnn.Dropout(dropout)\n","\t\t) if project_out else nn.Identity()\n","\n","\tdef forward(self, x):\n","\t\tqkv = self.to_qkv(x).chunk(3, dim=-1)\n","\t\tq, k, v = map(lambda t: rearrange(t, 'b p n (h d) -> b p h n d', h=self.heads), qkv)\n","\n","\t\tdots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\t\tattn = self.attend(dots)\n","\t\tout = torch.matmul(attn, v)\n","\t\tout = rearrange(out, 'b p h n d -> b p n (h d)')\n","\t\treturn self.to_out(out)\n","\n","\n","class Transformer(nn.Module):\n","\tdef __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tself.layers = nn.ModuleList([])\n","\t\tfor _ in range(depth):\n","\t\t\tself.layers.append(nn.ModuleList([\n","\t\t\t\tPreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n","\t\t\t\tPreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n","\t\t\t]))\n","\n","\tdef forward(self, x):\n","\t\tfor attn, ff in self.layers:\n","\t\t\tx = attn(x) + x\n","\t\t\tx = ff(x) + x\n","\t\treturn x\n","\n","class ChannelAttention(nn.Module):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n","        self.fc = nn.Sequential(\n","            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = self.fc(self.avg_pool(x))\n","        max_out = self.fc(self.max_pool(x))\n","        out = avg_out + max_out\n","        return self.sigmoid(out)\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n","        padding = 3 if kernel_size == 7 else 1\n","        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv(x)\n","        return self.sigmoid(x)\n","\n","class CBAM(nn.Module):\n","    def __init__(self, in_planes, ratio=16, kernel_size=7):\n","        super(CBAM, self).__init__()\n","        self.ca = ChannelAttention(in_planes, ratio)\n","        self.sa = SpatialAttention(kernel_size)\n","\n","    def forward(self, x):\n","        out = x * self.ca(x)\n","        return out * self.sa(out)\n","\n","class MV2Block(nn.Module):\n","    def __init__(self, inp, oup, stride=1, expand_ratio=4):\n","        super(MV2Block, self).__init__()\n","        assert stride in [1, 2]\n","\n","        hidden_dim = round(inp * expand_ratio)\n","        self.identity = stride == 1 and inp == oup\n","\n","        if expand_ratio == 1:\n","            self.conv = nn.Sequential(\n","                # dw\n","                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n","                nn.BatchNorm2d(hidden_dim),\n","                # nn.ReLU6(inplace=True),\n","                nn.SiLU(),\n","                # CBAM 注意力机制放置在 3x3 卷积层之后\n","                CBAM(hidden_dim),  # 添加 CBAM 注意力机制\n","                # pw-linear\n","                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(oup),\n","            )\n","        else:\n","            self.conv = nn.Sequential(\n","                # pw\n","                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(hidden_dim),\n","                # nn.ReLU6(inplace=True),\n","                nn.SiLU(),\n","                # dw\n","                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n","                nn.BatchNorm2d(hidden_dim),\n","                # nn.ReLU6(inplace=True),\n","                nn.SiLU(),\n","                # CBAM 注意力机制放置在 3x3 卷积层之后\n","                CBAM(hidden_dim),  # 添加 CBAM 注意力机制\n","                # pw-linear\n","                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(oup),\n","            )\n","\n","    def forward(self, x):\n","        if self.identity:\n","            return x + self.conv(x)\n","        else:\n","            return self.conv(x)\n","\n","# 实现ELA注意力机制\n","class ELAAttention(nn.Module):\n","    def __init__(self, channel, kernel_size):\n","        super().__init__()\n","        self.kernel_size = kernel_size\n","        self.pad = kernel_size // 2\n","        self.conv = nn.Conv1d(channel, channel, kernel_size, padding=self.pad, groups=channel, bias=False)\n","        self.gn = nn.GroupNorm(16, channel)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        b, c, h, w = x.size()\n","        x_h = torch.mean(x, dim=3, keepdim=True).view(b, c, h)\n","        x_w = torch.mean(x, dim=2, keepdim=True).view(b, c, w)\n","\n","        x_h = self.sigmoid(self.gn(self.conv(x_h))).view(b, c, h, 1)\n","        x_w = self.sigmoid(self.gn(self.conv(x_w))).view(b, c, 1, w)\n","        return x * x_h * x_w\n","\n","\n","\n","class MobileViTBlock(nn.Module):\n","    def __init__(self, dim, depth, channel, kernel_size, patch_size, mlp_dim, dropout=0.):\n","        super().__init__()\n","        self.ph, self.pw = patch_size\n","\n","        self.conv1 = Conv_BN_ReLU(channel, channel, kernel_size)\n","        self.conv2 = conv_1x1_bn(channel, dim)\n","\n","        # Transformer module includes attention mechanism internally\n","        self.transformer = Transformer(dim, depth, 1, 32, mlp_dim, dropout)\n","\n","        # ELA Attention module\n","        self.ela_attention = ELAAttention(channel, kernel_size)\n","\n","        # We will apply Transformer and ELAAttention in parallel to the feature map\n","        # Then, we fuse their outputs along with the original feature map from conv2\n","\n","        # Since we're fusing three feature maps: original, Transformer output, and ELA output,\n","        # we'll have 3 * channel output channels before reducing it back to the original channel size.\n","        self.conv3 = conv_1x1_bn(dim * 2 + channel, channel)  # Adjust for the tripled channel size\n","        self.conv4 = Conv_BN_ReLU(channel, channel, kernel_size)  # Process fused feature map\n","\n","    def forward(self, x):\n","        y = x.clone()\n","\n","        # Local representations\n","        x_local = self.conv1(x)\n","        x_local = self.conv2(x_local)\n","\n","        # 计算原始特征图的空间维度\n","        _, _, h, w = x_local.shape\n","\n","        # Transformer representations\n","        # 调整 x_local 的形状以适应 Transformer 的输入要求\n","        x_transformed = rearrange(x_local, 'b d (h ph) (w pw) -> b (h w) (ph pw) d', ph=self.ph, pw=self.pw)\n","        x_transformed = self.transformer(x_transformed)\n","        # 将 Transformer 的输出重新排列回原始的空间维度\n","        x_transformed = rearrange(x_transformed, 'b (h w) (ph pw) d -> b d (h ph) (w pw)', ph=self.ph, pw=self.pw, h=h // self.ph, w=w // self.pw)\n","\n","        # ELA Attention representations\n","        x_ela = self.ela_attention(y)\n","\n","        # Fusion of features from both attentions and the original\n","        # 确保x_ela, x_transformed, 和 x_local 在空间维度上一致\n","        x_fused = torch.cat((x_local, x_ela, x_transformed), 1)\n","\n","        # Reduce channel size and process\n","        x_reduced = self.conv3(x_fused)\n","        x_final = self.conv4(x_reduced)\n","\n","        return x_final\n","\n","\n","\n","\n","class MobileVit_v2(nn.Module):\n","\tdef __init__(self, image_size, dims, channels, num_classes, expansion=4, kernel_size=3, patch_size=(2, 2)):\n","\t\tsuper().__init__()\n","\t\tih, iw = image_size\n","\t\tph, pw = patch_size\n","\t\tassert ih % ph == 0 and iw % pw == 0\n","\n","\t\tL = [2, 4, 3]\n","\n","\t\tself.conv1 = Conv_BN_ReLU(3, channels[0], kernel=3, stride=2)\n","\n","\t\tself.mv2 = nn.ModuleList([])\n","\t\tself.mv2.append(MV2Block(channels[0], channels[1], 1, expansion))\n","\t\tself.mv2.append(MV2Block(channels[1], channels[2], 2, expansion))\n","\t\tself.mv2.append(MV2Block(channels[2], channels[3], 1, expansion))\n","\t\tself.mv2.append(MV2Block(channels[2], channels[3], 1, expansion))  # Repeat\n","\t\tself.mv2.append(MV2Block(channels[3], channels[4], 2, expansion))\n","\t\tself.mv2.append(MV2Block(channels[5], channels[6], 2, expansion))\n","\t\tself.mv2.append(MV2Block(channels[7], channels[8], 2, expansion))\n","\n","\t\tself.mvit = nn.ModuleList([])\n","\t\tself.mvit.append(MobileViTBlock(dims[0], L[0], channels[5], kernel_size, patch_size, int(dims[0] * 2)))\n","\t\tself.mvit.append(MobileViTBlock(dims[1], L[1], channels[7], kernel_size, patch_size, int(dims[1] * 4)))\n","\t\tself.mvit.append(MobileViTBlock(dims[2], L[2], channels[9], kernel_size, patch_size, int(dims[2] * 4)))\n","\n","\t\tself.conv2 = conv_1x1_bn(channels[-2], channels[-1])\n","\n","\t\tself.pool = nn.AvgPool2d(ih // 32, 1)\n","\t\tself.fc = nn.Linear(channels[-1], num_classes, bias=False)\n","\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = self.mv2[0](x)\n","\n","\t\tx = self.mv2[1](x)\n","\t\tx = self.mv2[2](x)\n","\t\tx = self.mv2[3](x)  # Repeat\n","\n","\t\tx = self.mv2[4](x)\n","\t\tx = self.mvit[0](x)\n","\n","\t\tx = self.mv2[5](x)\n","\t\tx = self.mvit[1](x)\n","\n","\t\tx = self.mv2[6](x)\n","\t\tx = self.mvit[2](x)\n","\t\tx = self.conv2(x)\n","\n","\t\tx = self.pool(x).view(-1, x.shape[1])\n","\t\tx = self.fc(x)\n","\t\treturn x\n","\n","\n","def mobilevit_xxs_v2():\n","\tdims = [64, 80, 96]\n","\tchannels = [16, 16, 24, 24, 48, 48, 64, 64, 80, 80, 320]\n","\treturn MobileVit_v2((256, 256), dims, channels, num_classes=54, expansion=2)\n","\n","\n","def mobilevit_xs_v2():\n","\tdims = [96, 120, 144]\n","\tchannels = [16, 32, 48, 48, 64, 64, 80, 80, 96, 96, 384]\n","\treturn MobileVit_v2((256, 256), dims, channels, num_classes=54)\n","\n","\n","def mobilevit_s_v2():\n","\tdims = [144, 192, 240]\n","\tchannels = [16, 32, 64, 64, 96, 96, 128, 128, 160, 160, 640]\n","\treturn MobileVit_v2((256, 256), dims, channels, num_classes=54)"],"metadata":{"id":"zYqJgFTBCFQi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#MobileViT\n","def _make_divisible(v, divisor, min_value=None):\n","\tif min_value is None:\n","\t\tmin_value = divisor\n","\tnew_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n","\t# Make sure that round down does not go down by more than 10%.\n","\tif new_v < 0.9 * v:\n","\t\tnew_v += divisor\n","\treturn new_v\n","\n","\n","def Conv_BN_ReLU(inp, oup, kernel, stride=1):\n","\treturn nn.Sequential(\n","\t\tnn.Conv2d(inp, oup, kernel_size=kernel, stride=stride, padding=1, bias=False),\n","\t\tnn.BatchNorm2d(oup),\n","\t\tnn.ReLU6(inplace=True)\n","\t)\n","\n","\n","def conv_1x1_bn(inp, oup):\n","\treturn nn.Sequential(\n","\t\tnn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n","\t\tnn.BatchNorm2d(oup),\n","\t\tnn.ReLU6(inplace=True)\n","\t)\n","\n","\n","class PreNorm(nn.Module):\n","\tdef __init__(self, dim, fn):\n","\t\tsuper().__init__()\n","\t\tself.norm = nn.LayerNorm(dim)\n","\t\tself.fn = fn\n","\n","\tdef forward(self, x, **kwargs):\n","\t\treturn self.fn(self.norm(x), **kwargs)\n","\n","\n","class FeedForward(nn.Module):\n","\tdef __init__(self, dim, hidden_dim, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tself.ffn = nn.Sequential(\n","\t\t\tnn.Linear(dim, hidden_dim),\n","\t\t\tnn.SiLU(),\n","\t\t\tnn.Dropout(dropout),\n","\t\t\tnn.Linear(hidden_dim, dim),\n","\t\t\tnn.Dropout(dropout)\n","\t\t)\n","\n","\tdef forward(self, x):\n","\t\treturn self.ffn(x)\n","\n","\n","class Attention(nn.Module):\n","\tdef __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tinner_dim = dim_head * heads\n","\t\tproject_out = not (heads == 1 and dim_head == dim)\n","\n","\t\tself.heads = heads\n","\t\tself.scale = dim_head ** -0.5\n","\n","\t\tself.attend = nn.Softmax(dim=-1)\n","\t\tself.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n","\n","\t\tself.to_out = nn.Sequential(\n","\t\t\tnn.Linear(inner_dim, dim),\n","\t\t\tnn.Dropout(dropout)\n","\t\t) if project_out else nn.Identity()\n","\n","\tdef forward(self, x):\n","\t\tqkv = self.to_qkv(x).chunk(3, dim=-1)\n","\t\tq, k, v = map(lambda t: rearrange(t, 'b p n (h d) -> b p h n d', h=self.heads), qkv)\n","\n","\t\tdots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\t\tattn = self.attend(dots)\n","\t\tout = torch.matmul(attn, v)\n","\t\tout = rearrange(out, 'b p h n d -> b p n (h d)')\n","\t\treturn self.to_out(out)\n","\n","\n","class Transformer(nn.Module):\n","\tdef __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tself.layers = nn.ModuleList([])\n","\t\tfor _ in range(depth):\n","\t\t\tself.layers.append(nn.ModuleList([\n","\t\t\t\tPreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n","\t\t\t\tPreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n","\t\t\t]))\n","\n","\tdef forward(self, x):\n","\t\tfor attn, ff in self.layers:\n","\t\t\tx = attn(x) + x\n","\t\t\tx = ff(x) + x\n","\t\treturn x\n","\n","\n","class MV2Block(nn.Module):\n","\tdef __init__(self, inp, oup, stride=1, expand_ratio=4):\n","\t\tsuper(MV2Block, self).__init__()\n","\t\tassert stride in [1, 2]\n","\n","\t\thidden_dim = round(inp * expand_ratio)\n","\t\tself.identity = stride == 1 and inp == oup\n","\n","\t\tif expand_ratio == 1:\n","\t\t\tself.conv = nn.Sequential(\n","\t\t\t\t# dw\n","\t\t\t\tnn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n","\t\t\t\tnn.BatchNorm2d(hidden_dim),\n","\t\t\t\t# nn.ReLU6(inplace=True),\n","\t\t\t\tnn.SiLU(),\n","\t\t\t\t# pw-linear\n","\t\t\t\tnn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n","\t\t\t\tnn.BatchNorm2d(oup),\n","\t\t\t)\n","\t\telse:\n","\t\t\tself.conv = nn.Sequential(\n","\t\t\t\t# pw\n","\t\t\t\tnn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n","\t\t\t\tnn.BatchNorm2d(hidden_dim),\n","\t\t\t\t# nn.ReLU6(inplace=True),\n","\t\t\t\tnn.SiLU(),\n","\t\t\t\t# dw\n","\t\t\t\tnn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n","\t\t\t\tnn.BatchNorm2d(hidden_dim),\n","\t\t\t\t# nn.ReLU6(inplace=True),\n","\t\t\t\tnn.SiLU(),\n","\t\t\t\t# pw-linear\n","\t\t\t\tnn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n","\t\t\t\tnn.BatchNorm2d(oup),\n","\t\t\t)\n","\n","\tdef forward(self, x):\n","\t\tif self.identity:\n","\t\t\treturn x + self.conv(x)\n","\t\telse:\n","\t\t\treturn self.conv(x)\n","\n","\n","class MobileViTBlock(nn.Module):\n","\tdef __init__(self, dim, depth, channel, kernel_size, patch_size, mlp_dim, dropout=0.):\n","\t\tsuper().__init__()\n","\t\tself.ph, self.pw = patch_size\n","\n","\t\tself.conv1 = Conv_BN_ReLU(channel, channel, kernel_size)\n","\t\tself.conv2 = conv_1x1_bn(channel, dim)\n","\n","\t\tself.transformer = Transformer(dim, depth, 1, 32, mlp_dim, dropout)\n","\n","\t\tself.conv3 = conv_1x1_bn(dim, channel)\n","\t\tself.conv4 = Conv_BN_ReLU(2 * channel, channel, kernel_size)\n","\n","\tdef forward(self, x):\n","\t\ty = x.clone()\n","\n","\t\t# Local representations\n","\t\tx = self.conv1(x)\n","\t\tx = self.conv2(x)\n","\n","\t\t# Global representations\n","\t\t_, _, h, w = x.shape\n","\t\tx = rearrange(x, 'b d (h ph) (w pw) -> b (ph pw) (h w) d', ph=self.ph, pw=self.pw)\n","\t\tx = self.transformer(x)\n","\t\tx = rearrange(x, 'b (ph pw) (h w) d -> b d (h ph) (w pw)', h=h // self.ph, w=w // self.pw, ph=self.ph,\n","\t\t              pw=self.pw)\n","\n","\t\t# Fusion\n","\t\tx = self.conv3(x)\n","\t\tx = torch.cat((x, y), 1)\n","\t\tx = self.conv4(x)\n","\t\treturn x\n","\n","\n","class MobileVit(nn.Module):\n","\tdef __init__(self, image_size, dims, channels, num_classes, expansion=4, kernel_size=3, patch_size=(2, 2)):\n","\t\tsuper().__init__()\n","\t\tih, iw = image_size\n","\t\tph, pw = patch_size\n","\t\tassert ih % ph == 0 and iw % pw == 0\n","\n","\t\tL = [2, 4, 3]\n","\n","\t\tself.conv1 = Conv_BN_ReLU(3, channels[0], kernel=3, stride=2)\n","\n","\t\tself.mv2 = nn.ModuleList([])\n","\t\tself.mv2.append(MV2Block(channels[0], channels[1], 1, expansion))\n","\t\tself.mv2.append(MV2Block(channels[1], channels[2], 2, expansion))\n","\t\tself.mv2.append(MV2Block(channels[2], channels[3], 1, expansion))\n","\t\tself.mv2.append(MV2Block(channels[2], channels[3], 1, expansion))  # Repeat\n","\t\tself.mv2.append(MV2Block(channels[3], channels[4], 2, expansion))\n","\t\tself.mv2.append(MV2Block(channels[5], channels[6], 2, expansion))\n","\t\tself.mv2.append(MV2Block(channels[7], channels[8], 2, expansion))\n","\n","\t\tself.mvit = nn.ModuleList([])\n","\t\tself.mvit.append(MobileViTBlock(dims[0], L[0], channels[5], kernel_size, patch_size, int(dims[0] * 2)))\n","\t\tself.mvit.append(MobileViTBlock(dims[1], L[1], channels[7], kernel_size, patch_size, int(dims[1] * 4)))\n","\t\tself.mvit.append(MobileViTBlock(dims[2], L[2], channels[9], kernel_size, patch_size, int(dims[2] * 4)))\n","\n","\t\tself.conv2 = conv_1x1_bn(channels[-2], channels[-1])\n","\n","\t\tself.pool = nn.AvgPool2d(ih // 32, 1)\n","\t\tself.fc = nn.Linear(channels[-1], num_classes, bias=False)\n","\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = self.mv2[0](x)\n","\n","\t\tx = self.mv2[1](x)\n","\t\tx = self.mv2[2](x)\n","\t\tx = self.mv2[3](x)  # Repeat\n","\n","\t\tx = self.mv2[4](x)\n","\t\tx = self.mvit[0](x)\n","\n","\t\tx = self.mv2[5](x)\n","\t\tx = self.mvit[1](x)\n","\n","\t\tx = self.mv2[6](x)\n","\t\tx = self.mvit[2](x)\n","\t\tx = self.conv2(x)\n","\n","\t\tx = self.pool(x).view(-1, x.shape[1])\n","\t\tx = self.fc(x)\n","\t\treturn x\n","\n","\n","def mobilevit_xxs():\n","\tdims = [64, 80, 96]\n","\tchannels = [16, 16, 24, 24, 48, 48, 64, 64, 80, 80, 320]\n","\treturn MobileVit((256, 256), dims, channels, num_classes=1000, expansion=2)\n","\n","\n","def mobilevit_xs():\n","\tdims = [96, 120, 144]\n","\tchannels = [16, 32, 48, 48, 64, 64, 80, 80, 96, 96, 384]\n","\treturn MobileVit((256, 256), dims, channels, num_classes=1000)\n","\n","\n","def mobilevit_s():\n","\tdims = [144, 192, 240]\n","\tchannels = [16, 32, 64, 64, 96, 96, 128, 128, 160, 160, 640]\n","\treturn MobileVit((256, 256), dims, channels, num_classes=54)"],"metadata":{"id":"w1Y9QyzsEcxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Subset\n","from sklearn.model_selection import KFold\n","from scipy.stats import ttest_rel\n","import torchvision.datasets as datasets\n","\n","# 检查GPU可用性并设置设备\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 加载模型并转移到GPU\n","model1 = torch.load('/content/drive/MyDrive/mv2/mv2_2_TSRD_m55_0.972.pth').to(device)\n","\n","# 确保模型在评估模式\n","model1.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZtwSiy7jB_g","executionInfo":{"status":"ok","timestamp":1718834406621,"user_tz":-720,"elapsed":2626,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"fc89a52c-6bf8-47d1-dcc1-cd3d694aceaa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MobileVit_v2(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU6(inplace=True)\n","  )\n","  (mv2): ModuleList(\n","    (0): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): CBAM(\n","          (ca): ChannelAttention(\n","            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","            (max_pool): AdaptiveMaxPool2d(output_size=1)\n","            (fc): Sequential(\n","              (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): ReLU(inplace=True)\n","              (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            )\n","            (sigmoid): Sigmoid()\n","          )\n","          (sa): SpatialAttention(\n","            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","            (sigmoid): Sigmoid()\n","          )\n","        )\n","        (7): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): CBAM(\n","          (ca): ChannelAttention(\n","            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","            (max_pool): AdaptiveMaxPool2d(output_size=1)\n","            (fc): Sequential(\n","              (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): ReLU(inplace=True)\n","              (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            )\n","            (sigmoid): Sigmoid()\n","          )\n","          (sa): SpatialAttention(\n","            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","            (sigmoid): Sigmoid()\n","          )\n","        )\n","        (7): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2-3): 2 x MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): CBAM(\n","          (ca): ChannelAttention(\n","            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","            (max_pool): AdaptiveMaxPool2d(output_size=1)\n","            (fc): Sequential(\n","              (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): ReLU(inplace=True)\n","              (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            )\n","            (sigmoid): Sigmoid()\n","          )\n","          (sa): SpatialAttention(\n","            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","            (sigmoid): Sigmoid()\n","          )\n","        )\n","        (7): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): CBAM(\n","          (ca): ChannelAttention(\n","            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","            (max_pool): AdaptiveMaxPool2d(output_size=1)\n","            (fc): Sequential(\n","              (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): ReLU(inplace=True)\n","              (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            )\n","            (sigmoid): Sigmoid()\n","          )\n","          (sa): SpatialAttention(\n","            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","            (sigmoid): Sigmoid()\n","          )\n","        )\n","        (7): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): CBAM(\n","          (ca): ChannelAttention(\n","            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","            (max_pool): AdaptiveMaxPool2d(output_size=1)\n","            (fc): Sequential(\n","              (0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): ReLU(inplace=True)\n","              (2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            )\n","            (sigmoid): Sigmoid()\n","          )\n","          (sa): SpatialAttention(\n","            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","            (sigmoid): Sigmoid()\n","          )\n","        )\n","        (7): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n","        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): CBAM(\n","          (ca): ChannelAttention(\n","            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","            (max_pool): AdaptiveMaxPool2d(output_size=1)\n","            (fc): Sequential(\n","              (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): ReLU(inplace=True)\n","              (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            )\n","            (sigmoid): Sigmoid()\n","          )\n","          (sa): SpatialAttention(\n","            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","            (sigmoid): Sigmoid()\n","          )\n","        )\n","        (7): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (mvit): ModuleList(\n","    (0): MobileViTBlock(\n","      (conv1): Sequential(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv2): Sequential(\n","        (0): Conv2d(96, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (transformer): Transformer(\n","        (layers): ModuleList(\n","          (0-1): 2 x ModuleList(\n","            (0): PreNorm(\n","              (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n","              (fn): Attention(\n","                (attend): Softmax(dim=-1)\n","                (to_qkv): Linear(in_features=144, out_features=96, bias=False)\n","                (to_out): Sequential(\n","                  (0): Linear(in_features=32, out_features=144, bias=True)\n","                  (1): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): PreNorm(\n","              (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n","              (fn): FeedForward(\n","                (ffn): Sequential(\n","                  (0): Linear(in_features=144, out_features=288, bias=True)\n","                  (1): SiLU()\n","                  (2): Dropout(p=0.0, inplace=False)\n","                  (3): Linear(in_features=288, out_features=144, bias=True)\n","                  (4): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (ela_attention): ELAAttention(\n","        (conv): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(1,), groups=96, bias=False)\n","        (gn): GroupNorm(16, 96, eps=1e-05, affine=True)\n","        (sigmoid): Sigmoid()\n","      )\n","      (conv3): Sequential(\n","        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv4): Sequential(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (1): MobileViTBlock(\n","      (conv1): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv2): Sequential(\n","        (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (transformer): Transformer(\n","        (layers): ModuleList(\n","          (0-3): 4 x ModuleList(\n","            (0): PreNorm(\n","              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","              (fn): Attention(\n","                (attend): Softmax(dim=-1)\n","                (to_qkv): Linear(in_features=192, out_features=96, bias=False)\n","                (to_out): Sequential(\n","                  (0): Linear(in_features=32, out_features=192, bias=True)\n","                  (1): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): PreNorm(\n","              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","              (fn): FeedForward(\n","                (ffn): Sequential(\n","                  (0): Linear(in_features=192, out_features=768, bias=True)\n","                  (1): SiLU()\n","                  (2): Dropout(p=0.0, inplace=False)\n","                  (3): Linear(in_features=768, out_features=192, bias=True)\n","                  (4): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (ela_attention): ELAAttention(\n","        (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n","        (gn): GroupNorm(16, 128, eps=1e-05, affine=True)\n","        (sigmoid): Sigmoid()\n","      )\n","      (conv3): Sequential(\n","        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv4): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (2): MobileViTBlock(\n","      (conv1): Sequential(\n","        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv2): Sequential(\n","        (0): Conv2d(160, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (transformer): Transformer(\n","        (layers): ModuleList(\n","          (0-2): 3 x ModuleList(\n","            (0): PreNorm(\n","              (norm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n","              (fn): Attention(\n","                (attend): Softmax(dim=-1)\n","                (to_qkv): Linear(in_features=240, out_features=96, bias=False)\n","                (to_out): Sequential(\n","                  (0): Linear(in_features=32, out_features=240, bias=True)\n","                  (1): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): PreNorm(\n","              (norm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n","              (fn): FeedForward(\n","                (ffn): Sequential(\n","                  (0): Linear(in_features=240, out_features=960, bias=True)\n","                  (1): SiLU()\n","                  (2): Dropout(p=0.0, inplace=False)\n","                  (3): Linear(in_features=960, out_features=240, bias=True)\n","                  (4): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (ela_attention): ELAAttention(\n","        (conv): Conv1d(160, 160, kernel_size=(3,), stride=(1,), padding=(1,), groups=160, bias=False)\n","        (gn): GroupNorm(16, 160, eps=1e-05, affine=True)\n","        (sigmoid): Sigmoid()\n","      )\n","      (conv3): Sequential(\n","        (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv4): Sequential(\n","        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU6(inplace=True)\n","  )\n","  (pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","  (fc): Linear(in_features=640, out_features=54, bias=False)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 检查GPU可用性并设置设备\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 加载模型并转移到GPU\n","model2 = torch.load('/content/drive/MyDrive/myvit/mv0_t/modelv0_TSRD_m49_0.899.pth').to(device)\n","\n","\n","# 确保模型在评估模式\n","model2.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGCjTmj5jGDS","executionInfo":{"status":"ok","timestamp":1718835333311,"user_tz":-720,"elapsed":2431,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"a5ce3443-de47-4691-a07b-f66b04b42168"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MobileVit(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU6(inplace=True)\n","  )\n","  (mv2): ModuleList(\n","    (0): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2-3): 2 x MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): MV2Block(\n","      (conv): Sequential(\n","        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU()\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n","        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): SiLU()\n","        (6): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (mvit): ModuleList(\n","    (0): MobileViTBlock(\n","      (conv1): Sequential(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv2): Sequential(\n","        (0): Conv2d(96, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (transformer): Transformer(\n","        (layers): ModuleList(\n","          (0-1): 2 x ModuleList(\n","            (0): PreNorm(\n","              (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n","              (fn): Attention(\n","                (attend): Softmax(dim=-1)\n","                (to_qkv): Linear(in_features=144, out_features=96, bias=False)\n","                (to_out): Sequential(\n","                  (0): Linear(in_features=32, out_features=144, bias=True)\n","                  (1): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): PreNorm(\n","              (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n","              (fn): FeedForward(\n","                (ffn): Sequential(\n","                  (0): Linear(in_features=144, out_features=288, bias=True)\n","                  (1): SiLU()\n","                  (2): Dropout(p=0.0, inplace=False)\n","                  (3): Linear(in_features=288, out_features=144, bias=True)\n","                  (4): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (conv3): Sequential(\n","        (0): Conv2d(144, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv4): Sequential(\n","        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (1): MobileViTBlock(\n","      (conv1): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv2): Sequential(\n","        (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (transformer): Transformer(\n","        (layers): ModuleList(\n","          (0-3): 4 x ModuleList(\n","            (0): PreNorm(\n","              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","              (fn): Attention(\n","                (attend): Softmax(dim=-1)\n","                (to_qkv): Linear(in_features=192, out_features=96, bias=False)\n","                (to_out): Sequential(\n","                  (0): Linear(in_features=32, out_features=192, bias=True)\n","                  (1): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): PreNorm(\n","              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","              (fn): FeedForward(\n","                (ffn): Sequential(\n","                  (0): Linear(in_features=192, out_features=768, bias=True)\n","                  (1): SiLU()\n","                  (2): Dropout(p=0.0, inplace=False)\n","                  (3): Linear(in_features=768, out_features=192, bias=True)\n","                  (4): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (conv3): Sequential(\n","        (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv4): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (2): MobileViTBlock(\n","      (conv1): Sequential(\n","        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv2): Sequential(\n","        (0): Conv2d(160, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (transformer): Transformer(\n","        (layers): ModuleList(\n","          (0-2): 3 x ModuleList(\n","            (0): PreNorm(\n","              (norm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n","              (fn): Attention(\n","                (attend): Softmax(dim=-1)\n","                (to_qkv): Linear(in_features=240, out_features=96, bias=False)\n","                (to_out): Sequential(\n","                  (0): Linear(in_features=32, out_features=240, bias=True)\n","                  (1): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): PreNorm(\n","              (norm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n","              (fn): FeedForward(\n","                (ffn): Sequential(\n","                  (0): Linear(in_features=240, out_features=960, bias=True)\n","                  (1): SiLU()\n","                  (2): Dropout(p=0.0, inplace=False)\n","                  (3): Linear(in_features=960, out_features=240, bias=True)\n","                  (4): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (conv3): Sequential(\n","        (0): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (conv4): Sequential(\n","        (0): Conv2d(320, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU6(inplace=True)\n","  )\n","  (pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","  (fc): Linear(in_features=640, out_features=54, bias=False)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#tsrd\n","\n","dataset_test = datasets.ImageFolder('/content/TSRD/TSRD_dataset/Test', transform=transform_test)\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# 用于收集每个模型在每个折上的性能\n","results_model1 = []\n","results_model2 = []\n","\n","def evaluate_model(model, loader):\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total\n","\n","# K 折交叉验证\n","for train_index, test_index in kfold.split(dataset_test):\n","    print(f'Fold {5}: test_index {test_index[:5]}')  # 打印一部分索引以进行检查\n","    test_subsampler = Subset(dataset_test, test_index)\n","\n","    test_loader = torch.utils.data.DataLoader(test_subsampler, batch_size=32, shuffle=False)\n","\n","    # 训练模型 (这里假设模型已经训练完成，直接评估)\n","    acc_model1 = evaluate_model(model1, test_loader)\n","    acc_model2 = evaluate_model(model2, test_loader)\n","\n","    results_model1.append(acc_model1)\n","    results_model2.append(acc_model2)\n","\n","# T检验\n","t_stat, p_value = ttest_rel(results_model1, results_model2)\n","print(f'T-statistic: {t_stat}, P-value: {p_value}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Srffk8pR-7rL","executionInfo":{"status":"ok","timestamp":1718835357331,"user_tz":-720,"elapsed":22555,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"1048833a-035a-4ab5-d900-f29e43504d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 5: test_index [23 29 30 32 44]\n","Fold 5: test_index [ 2  6 15 18 31]\n","Fold 5: test_index [ 0  3  5  7 10]\n","Fold 5: test_index [ 4  9 11 16 17]\n","Fold 5: test_index [ 1  8 13 14 20]\n","T-statistic: 12.349177318962608, P-value: 0.00024708618161364696\n"]}]},{"cell_type":"code","source":["##GTSRB\n","dataset_test = datasets.ImageFolder('/content/datasets/test', transform=transform_test)\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# 用于收集每个模型在每个折上的性能\n","results_model1 = []\n","results_model2 = []\n","\n","def evaluate_model(model, loader):\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total\n","\n","# K 折交叉验证\n","for train_index, test_index in kfold.split(dataset_test):\n","    print(f'Fold {5}: test_index {test_index[:5]}')  # 打印一部分索引以进行检查\n","    test_subsampler = Subset(dataset_test, test_index)\n","\n","    test_loader = torch.utils.data.DataLoader(test_subsampler, batch_size=32, shuffle=False)\n","\n","    # 训练模型 (这里假设模型已经训练完成，直接评估)\n","    acc_model1 = evaluate_model(model1, test_loader)\n","    acc_model2 = evaluate_model(model2, test_loader)\n","\n","    results_model1.append(acc_model1)\n","    results_model2.append(acc_model2)\n","\n","# T检验\n","t_stat, p_value = ttest_rel(results_model1, results_model2)\n","print(f'T-statistic: {t_stat}, P-value: {p_value}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_mpOB0anpOs","executionInfo":{"status":"ok","timestamp":1718786507150,"user_tz":-720,"elapsed":87835,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"1b43e9b8-044a-427c-b764-2179c855243d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 5: test_index [ 0  3  8 14 17]\n","Fold 5: test_index [10 12 20 23 29]\n","Fold 5: test_index [15 26 27 28 34]\n","Fold 5: test_index [ 2  6  7 18 22]\n","Fold 5: test_index [ 1  4  5  9 11]\n","T-statistic: 3.172049109212676, P-value: 0.03379140128372741\n"]}]},{"cell_type":"code","source":["##btsd\n","dataset_test = datasets.ImageFolder('/content/BelgiumTSC/BelgiumTSC/Testing', transform=transform_test)\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# 用于收集每个模型在每个折上的性能\n","results_model1 = []\n","results_model2 = []\n","\n","def evaluate_model(model, loader):\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total\n","\n","# K 折交叉验证\n","for train_index, test_index in kfold.split(dataset_test):\n","    print(f'Fold {5}: test_index {test_index[:5]}')  # 打印一部分索引以进行检查\n","    test_subsampler = Subset(dataset_test, test_index)\n","\n","    test_loader = torch.utils.data.DataLoader(test_subsampler, batch_size=32, shuffle=False)\n","\n","    # 训练模型 (这里假设模型已经训练完成，直接评估)\n","    acc_model1 = evaluate_model(model1, test_loader)\n","    acc_model2 = evaluate_model(model2, test_loader)\n","\n","    results_model1.append(acc_model1)\n","    results_model2.append(acc_model2)\n","\n","# T检验\n","t_stat, p_value = ttest_rel(results_model1, results_model2)\n","print(f'T-statistic: {t_stat}, P-value: {p_value}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLrWfHDVqdVs","executionInfo":{"status":"ok","timestamp":1718787862999,"user_tz":-720,"elapsed":18208,"user":{"displayName":"宋世骐","userId":"10822952913289090944"}},"outputId":"dde3193a-9c2e-4c93-db58-3947e3c1d1dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 5: test_index [25 29 43 44 48]\n","Fold 5: test_index [ 8 13 18 20 23]\n","Fold 5: test_index [ 2  6 10 14 15]\n","Fold 5: test_index [0 3 5 7 9]\n","Fold 5: test_index [ 1  4 11 16 19]\n","T-statistic: 2.060488785479736, P-value: 0.10839243802227273\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.5"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}